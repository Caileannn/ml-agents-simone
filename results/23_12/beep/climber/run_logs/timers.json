{
    "name": "root",
    "gauges": {
        "c_Walker.Policy.Entropy.mean": {
            "value": 1.2556761503219604,
            "min": 1.2556761503219604,
            "max": 1.3246440887451172,
            "count": 19
        },
        "c_Walker.Policy.Entropy.sum": {
            "value": 124000.53125,
            "min": 117782.125,
            "max": 159550.734375,
            "count": 19
        },
        "c_Walker.Environment.EpisodeLength.mean": {
            "value": 124.5357590966123,
            "min": 124.5357590966123,
            "max": 898.4234234234234,
            "count": 19
        },
        "c_Walker.Environment.EpisodeLength.sum": {
            "value": 99255.0,
            "min": 99255.0,
            "max": 100679.0,
            "count": 19
        },
        "c_Walker.Step.mean": {
            "value": 1899979.0,
            "min": 99953.0,
            "max": 1899979.0,
            "count": 19
        },
        "c_Walker.Step.sum": {
            "value": 1899979.0,
            "min": 99953.0,
            "max": 1899979.0,
            "count": 19
        },
        "c_Walker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 4.40432596206665,
            "min": -0.3148682415485382,
            "max": 157.8104705810547,
            "count": 19
        },
        "c_Walker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3510.247802734375,
            "min": -51.638389587402344,
            "max": 43082.2578125,
            "count": 19
        },
        "c_Walker.Environment.CumulativeReward.mean": {
            "value": 6.26586208424275,
            "min": -8.032439066652666,
            "max": 6.372119806282711,
            "count": 19
        },
        "c_Walker.Environment.CumulativeReward.sum": {
            "value": 4993.892081141472,
            "min": -915.6980535984039,
            "max": 4993.892081141472,
            "count": 19
        },
        "c_Walker.Policy.ExtrinsicReward.mean": {
            "value": 6.26586208424275,
            "min": -8.032439066652666,
            "max": 6.372119806282711,
            "count": 19
        },
        "c_Walker.Policy.ExtrinsicReward.sum": {
            "value": 4993.892081141472,
            "min": -915.6980535984039,
            "max": 4993.892081141472,
            "count": 19
        },
        "c_Walker.Losses.PolicyLoss.mean": {
            "value": 0.01686110115105597,
            "min": 0.015054962034676767,
            "max": 0.019226460586044897,
            "count": 19
        },
        "c_Walker.Losses.PolicyLoss.sum": {
            "value": 0.08430550575527984,
            "min": 0.06451406800333644,
            "max": 0.0948254270440278,
            "count": 19
        },
        "c_Walker.Losses.ValueLoss.mean": {
            "value": 1.8318829488754271,
            "min": 0.47654878914356225,
            "max": 588.7900824228923,
            "count": 19
        },
        "c_Walker.Losses.ValueLoss.sum": {
            "value": 9.159414744377136,
            "min": 1.9391973694165547,
            "max": 2355.160329691569,
            "count": 19
        },
        "c_Walker.Policy.LearningRate.mean": {
            "value": 0.000244360194546608,
            "min": 0.000244360194546608,
            "max": 0.0002984442080185975,
            "count": 19
        },
        "c_Walker.Policy.LearningRate.sum": {
            "value": 0.0012218009727330398,
            "min": 0.0010381135439621698,
            "max": 0.0014781915372694895,
            "count": 19
        },
        "c_Walker.Policy.Epsilon.mean": {
            "value": 0.18145339200000002,
            "min": 0.18145339200000002,
            "max": 0.19948140250000002,
            "count": 19
        },
        "c_Walker.Policy.Epsilon.sum": {
            "value": 0.9072669600000001,
            "min": 0.74603783,
            "max": 0.9927305100000001,
            "count": 19
        },
        "c_Walker.Policy.Beta.mean": {
            "value": 0.0040745242608,
            "min": 0.0040745242608,
            "max": 0.004974121984749999,
            "count": 19
        },
        "c_Walker.Policy.Beta.sum": {
            "value": 0.020372621304,
            "min": 0.017307287717000002,
            "max": 0.024637252449000006,
            "count": 19
        },
        "c_Walker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 19
        },
        "c_Walker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 19
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1702915855",
        "python_version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\caile\\anaconda3\\Scripts\\mlagents-learn --run-id 23_12/beep/climber ./config/ppo/ChairWalker/ChairWalker.yaml --force --initialize-from 23_12/beep/walker",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1702917140"
    },
    "total": 1285.9522929,
    "count": 1,
    "self": 0.0044100000000071304,
    "children": {
        "run_training.setup": {
            "total": 0.16617290000000007,
            "count": 1,
            "self": 0.16617290000000007
        },
        "TrainerController.start_learning": {
            "total": 1285.78171,
            "count": 1,
            "self": 0.6023298000072828,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.2708197,
                    "count": 1,
                    "self": 9.2708197
                },
                "TrainerController.advance": {
                    "total": 1275.7531849999928,
                    "count": 33664,
                    "self": 0.5705002999739008,
                    "children": {
                        "env_step": {
                            "total": 869.5910078000138,
                            "count": 33664,
                            "self": 789.4796600000152,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 79.73178749998537,
                                    "count": 33664,
                                    "self": 2.2886824999814763,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 77.4431050000039,
                                            "count": 29838,
                                            "self": 77.4431050000039
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.37956030001324237,
                                    "count": 33663,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1276.4829857000077,
                                            "count": 33663,
                                            "is_parallel": true,
                                            "self": 564.8443257999916,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0018546999999990987,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00014159999999918682,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.001713099999999912,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.001713099999999912
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 711.6368052000162,
                                                    "count": 33663,
                                                    "is_parallel": true,
                                                    "self": 20.94990870002971,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 27.64636379999319,
                                                            "count": 33663,
                                                            "is_parallel": true,
                                                            "self": 27.64636379999319
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 607.9575184000014,
                                                            "count": 33663,
                                                            "is_parallel": true,
                                                            "self": 607.9575184000014
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 55.083014299991845,
                                                            "count": 33663,
                                                            "is_parallel": true,
                                                            "self": 4.455791099994784,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 50.62722319999706,
                                                                    "count": 134652,
                                                                    "is_parallel": true,
                                                                    "self": 50.62722319999706
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 405.59167690000504,
                            "count": 33663,
                            "self": 2.3005638999980533,
                            "children": {
                                "process_trajectory": {
                                    "total": 99.5700168000062,
                                    "count": 33663,
                                    "self": 99.23882050000627,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.33119629999993094,
                                            "count": 3,
                                            "self": 0.33119629999993094
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 303.7210962000008,
                                    "count": 91,
                                    "self": 237.24152030000332,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 66.47957589999746,
                                            "count": 2730,
                                            "self": 66.47957589999746
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.000000318337698e-07,
                    "count": 1,
                    "self": 9.000000318337698e-07
                },
                "TrainerController._save_models": {
                    "total": 0.15537459999995917,
                    "count": 1,
                    "self": 0.04280360000007022,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.11257099999988895,
                            "count": 1,
                            "self": 0.11257099999988895
                        }
                    }
                }
            }
        }
    }
}